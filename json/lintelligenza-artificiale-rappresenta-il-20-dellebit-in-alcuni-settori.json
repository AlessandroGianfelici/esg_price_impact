{"date": "20210325", "category": "L'opinione di Masja Zandbergen, Head of Sustainability Integration di Robeco", "title": "L\u2019intelligenza artificiale rappresenta il 20% dell\u2019EBIT in alcuni settori", "text": "Gli algoritmi usati dai social media fanno s\u00ec che le persone interessate ad un determinato argomento vedano solo informazioni che confermano questa ipotesi e non essere esposte ad altri fatti e opinioni, il che pu\u00f2 essere dannoso. Un esempio \u00e8 stato la possibilit\u00e0 di frodi elettorali durante le presidenziali statunitensi.Una ricerca di McKinsey dimostra che molte organizzazioni utilizzano l\u2019intelligenza artificiale (IA) quale strumento per generare valore. Le imprese che ne fanno un uso maggiore provengono da una variet\u00e0 di settori che gi\u00e0 attribuiscono all\u2019IA il 20% o pi\u00f9 degli utili al lordo di interessi e imposte (EBIT) delle loro organizzazioni.Anche se questo \u00e8 un segnale favorevole per gli investitori, siamo fermamente convinti che le imprese dovrebbero anche affrontare i rischi legati all\u2019uso dell\u2019IA. Lo stesso studio rileva che solo una minoranza di aziende \u00e8 consapevole di tali rischi, e che un numero ancora minore si adopera per ridurli. Le aziende pronte ad affrontare il futuro non dovrebbero aspettare la regolamentazione, ma assumersi la responsabilit\u00e0 fin da subito. Quali sono alcuni dei problemi sociali posti dall\u2019IA? Diritti civili: i sistemi di IA sono sempre pi\u00f9 utilizzati in aree socialmente sensibili come l\u2019istruzione, l\u2019occupazione, l\u2019edilizia abitativa, il credit scoring, l\u2019attivit\u00e0 di polizia e la giustizia penale. Spesso vengono impiegati senza conoscenza del contesto o la prestazione di un consenso informato, e quindi costituiscono una minaccia per i diritti e le libert\u00e0 civili. Ad esempio, il diritto alla privacy \u00e8 a rischio, soprattutto con il crescente utilizzo delle tecnologie di riconoscimento facciale, dove \u00e8 quasi impossibile sottrarsi alla loro applicazione. Lavoro e automazione: l\u2019automazione basata sull\u2019IA nei luoghi di lavoro pu\u00f2 migliorare l\u2019efficienza e ridurre la quantit\u00e0 di mansioni ripetitive. Le occupazioni sono destinate a cambiare poich\u00e9 l\u2019automazione crea posti di lavoro in alcuni settori e sostituisce i lavoratori in altri. L\u2019IA pu\u00f2 comportare anche una maggiore sorveglianza sul lavoro svolto; pertanto, le aziende devono assicurare che i loro dipendenti siano pienamente consapevoli di come vengono monitorati e valutati. Un altro esempio specifico del settore tecnologico \u00e8 il lavoro nascosto delle persone che contribuiscono a creare, mantenere e testare sistemi di IA. Questo tipo di lavoro invisibile, ripetitivo e spesso non riconosciuto \u2013 chiamato anche \u201cclick working\u201d \u2013 \u00e8 remunerato a cottimo ed \u00e8 spesso sottopagato. Sicurezza e responsabilit\u00e0: l\u2019IA \u00e8 gi\u00e0 utilizzata per prendere decisioni in molti settori, tra cui i servizi finanziari, gli ospedali e le reti energetiche. A causa delle pressioni di mercato, diversi sistemi di IA sono stati utilizzati prima che ne fosse assicurata la sicurezza tecnica. Data la possibilit\u00e0 che si verifichino incidenti, se vogliamo che i sistemi di IA prendano importanti decisioni all\u2019interno della societ\u00e0 \u00e8 essenziale che qualcuno se ne assuma la responsabilit\u00e0. Distorsioni: la questione pi\u00f9 comunemente discussa nei sistemi di IA \u00e8 che sono inclini a distorsioni che possono rispecchiare e persino rafforzare i pregiudizi e le disuguaglianze sociali. Queste distorsioni potrebbero derivare da dati che riflettono le discriminazioni esistenti o che non sono rappresentativi della societ\u00e0 moderna. Anche se i dati sottostanti sono privi di distorsioni, il loro utilizzo potrebbe crearne di nuove in vari modi. Un rapporto pubblicato dall\u2019UNESCO ha rivelato che gli assistenti vocali basati sull\u2019IA, da Alexa di Amazon a Siri di Apple, rafforzano i pregiudizi di genere. Secondo il rapporto, questi assistenti vocali hanno voci femminili di default, e sono programmati in modo da suggerire che le donne sono sottomesse. Inoltre, l\u2019utilizzo di modelli sbagliati, o di modelli con caratteristiche inavvertitamente discriminatorie, potrebbe condurre a un sistema distorto. Un\u2019altra questione connessa alle distorsioni \u00e8 il problema della \u201cscatola nera\u201d, per cui \u00e8 impossibile comprendere la procedura seguita dal sistema di IA per giungere a determinate decisioni; ne consegue che le distorsioni possono manifestarsi anche inconsciamente. Infine, negli algoritmi si potrebbero incorporare distorsioni intenzionali. Moderazione dei contenuti sotto i riflettori Le piattaforme di social media utilizzano algoritmi di moderazione dei contenuti e team di valutazione per monitorare i contributi generati dagli utenti, sulla base di una serie di regole e linee guida prestabilite. Il lavoro di moderazione dei contenuti richiede una forte resistenza psicologica; spesso non \u00e8 idoneo a essere svolto da casa con i membri della famiglia nella stessa stanza. Di conseguenza, durante la pandemia di Covid-19 le aziende hanno dovuto ridimensionare la quantit\u00e0 di contenuti che potevano essere controllati.La rilevanza e l\u2019importanza della moderazione dei contenuti \u00e8 emersa in tutta chiarezza dalla campagna #StopHateForProfit, che ha messo in evidenza la redditivit\u00e0 dei discorsi nocivi e della disinformazione su Facebook. La campagna ha indotto pi\u00f9 di 1.000 inserzionisti \u2013 tra cui grandi player come Target, Unilever e Verizon \u2013 a boicottare le pubblicit\u00e0 su Facebook nel luglio 2020. L\u2019attenzione alla moderazione dei contenuti \u00e8 continuata anche durante la campagna elettorale statunitense, con l\u2019adozione di linee guida e procedure pi\u00f9 rigorose da parte di tutti i principali social media.In un\u2019ottica di investimento, scorgiamo grandi opportunit\u00e0 in questo trend. Tuttavia, siamo anche consapevoli che l\u2019IA pu\u00f2 essere accompagnata da effetti indesiderati che le societ\u00e0 dovrebbero affrontare. C\u2019\u00e8 ancora molta strada da fare."}